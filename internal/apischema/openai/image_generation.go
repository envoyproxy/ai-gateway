// Copyright Envoy AI Gateway Authors
// SPDX-License-Identifier: Apache-2.0
// The full text of the Apache license is available in the LICENSE file at
// the root of the repo.

// Package openai contains the OpenAI Images API schema definitions.
// This follows the OpenAI Images API specification for image generation.
// Reference: https://platform.openai.com/docs/api-reference/images
package openai

import (
	"encoding/json"
	"errors"
	"fmt"
	"slices"
	"strings"
)

// Image generation model constants
const (
	ModelDalle2    = "dall-e-2"
	ModelDalle3    = "dall-e-3"
	ModelGPTImage1 = "gpt-image-1"
)

// Image size constants
const (
	// ImageSize256x256: DALL-E 2
	ImageSize256x256 = "256x256"
	// ImageSize512x512: DALL-E 2
	ImageSize512x512 = "512x512"
	// ImageSize1024x1024: DALL-E 2, DALL-E 3
	ImageSize1024x1024 = "1024x1024"
	// ImageSize1792x1024: DALL-E 3 only
	ImageSize1792x1024 = "1792x1024"
	// ImageSize1024x1792: DALL-E 3 only
	ImageSize1024x1792 = "1024x1792"
	// ImageSize1536x1024: GPT-Image-1 (landscape)
	ImageSize1536x1024 = "1536x1024"
	// ImageSize1024x1536: GPT-Image-1 (portrait)
	ImageSize1024x1536 = "1024x1536"
	// ImageSizeAuto: GPT-Image-1 auto
	ImageSizeAuto = "auto"
)

// Image quality constants
const (
	// ImageQualityStandard is the standard quality setting
	ImageQualityStandard = "standard"
	// ImageQualityHD is the high definition quality setting (DALL-E 3 only)
	ImageQualityHD = "hd"
	// ImageQualityAuto automatically selects the best quality for the given model
	ImageQualityAuto = "auto"
	// ImageQualityHigh is a quality setting for GPT-Image-1
	ImageQualityHigh = "high"
	// ImageQualityMedium is a quality setting for GPT-Image-1
	ImageQualityMedium = "medium"
	// ImageQualityLow is a quality setting for GPT-Image-1
	ImageQualityLow = "low"
)

// Image style constants (DALL-E 3 only)
const (
	// ImageStyleVivid is the vivid style setting (DALL-E 3 only)
	ImageStyleVivid = "vivid"
	// ImageStyleNatural is the natural style setting (DALL-E 3 only)
	ImageStyleNatural = "natural"
)

// Image response format constants
const (
	// ImageResponseFormatURL returns the image as a URL
	ImageResponseFormatURL = "url"
	// ImageResponseFormatB64JSON returns the image as base64-encoded JSON
	ImageResponseFormatB64JSON = "b64_json"
)

// Image background constants (GPT-Image-1 only)
const (
	// ImageBackgroundAuto automatically determines the best background for the image
	ImageBackgroundAuto = "auto"
	// ImageBackgroundTransparent sets a transparent background
	ImageBackgroundTransparent = "transparent"
	// ImageBackgroundOpaque sets an opaque background
	ImageBackgroundOpaque = "opaque"
)

// Image moderation constants (GPT-Image-1 only)
const (
	// ImageModerationAuto is the default content-moderation level
	ImageModerationAuto = "auto"
	// ImageModerationLow provides less restrictive filtering
	ImageModerationLow = "low"
)

// Image output format constants (GPT-Image-1 only)
const (
	// ImageOutputFormatPNG is the PNG output format
	ImageOutputFormatPNG = "png"
	// ImageOutputFormatJPEG is the JPEG output format
	ImageOutputFormatJPEG = "jpeg"
	// ImageOutputFormatWEBP is the WebP output format
	ImageOutputFormatWEBP = "webp"
)

// ImageGenerationRequest represents a request to the OpenAI Images API.
// Reference: https://platform.openai.com/docs/api-reference/images/create
type ImageGenerationRequest struct {
	// Prompt: A text description of the desired image(s). The maximum length is 32000 characters for gpt-image-1,
	// 1000 characters for dall-e-2, and 4000 characters for dall-e-3.
	// Required.
	Prompt string `json:"prompt"`

	// Background: Allows to set transparency for the background of the generated image(s). Must be one of transparent, opaque or auto.
	// This parameter is only supported for gpt-image-1. Defaults to "auto".
	Background string `json:"background,omitempty"`

	// Model: The model to use for image generation. Defaults to "dall-e-2".
	// One of "dall-e-2", "dall-e-3", or "gpt-image-1".
	Model string `json:"model,omitempty"`

	// Moderation: Control the content-moderation level for images generated by gpt-image-1.
	// Must be either "low" for less restrictive filtering or "auto" (default value).
	// This parameter is only supported for gpt-image-1. Defaults to "auto".
	Moderation string `json:"moderation,omitempty"`

	// N: The number of images to generate. Must be between 1 and 10 for dall-e-2, exactly 1 for dall-e-3,
	// and between 1 and 10 for gpt-image-1.
	// Defaults to 1.
	N *int `json:"n,omitempty"`

	// OutputCompression: The compression level (0-100%) for the generated images.
	// This parameter is only supported for gpt-image-1 with the webp or jpeg output formats.
	// Defaults to 100.
	OutputCompression *int `json:"output_compression,omitempty"`

	// OutputFormat: The format in which the generated images are returned. This parameter is only supported for gpt-image-1.
	// Must be one of png, jpeg, or webp. Defaults to "png".
	OutputFormat string `json:"output_format,omitempty"`

	// PartialImages: The number of partial images to generate. This parameter is used for streaming responses
	// that return partial images. Value must be between 0 and 3.
	// When set to 0, the response will be a single image sent in one streaming event.
	// Defaults to 0.
	PartialImages *int `json:"partial_images,omitempty"`

	// Quality: The quality of the image that will be generated. "auto" will automatically select the best quality
	// for the given model. "high", "medium" and "low" are supported for gpt-image-1.
	// "hd" and "standard" are supported for dall-e-3. "standard" is the only option for dall-e-2.
	// Defaults to "auto".
	Quality string `json:"quality,omitempty"`

	// ResponseFormat: The format in which the generated images are returned. Must be one of url or b64_json.
	// This parameter isn't supported for gpt-image-1 which will always return base64-encoded images.
	// Defaults to "url".
	ResponseFormat string `json:"response_format,omitempty"`

	// Size: The size of the generated images. Must be one of 256x256, 512x512, or 1024x1024 for dall-e-2,
	// one of 1024x1024, 1792x1024, or 1024x1792 for dall-e-3, and one of 1024x1024, 1536x1024 (landscape),
	// 1024x1536 (portrait), or auto for gpt-image-1.
	// Defaults to "auto".
	Size string `json:"size,omitempty"`

	// Stream: Generate the image in streaming mode. Defaults to false.
	// This parameter is only supported for gpt-image-1.
	Stream *bool `json:"stream,omitempty"`

	// Style: The style of the generated images. This parameter is only supported for dall-e-3.
	// Must be one of "vivid" or "natural". Defaults to "vivid".
	Style string `json:"style,omitempty"`

	// User: A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
	User string `json:"user,omitempty"`
}

// Validate validates the ImageGenerationRequest according to OpenAI Images API constraints.
func (r *ImageGenerationRequest) Validate() error {
	// Set defaults first
	if r.Model == "" {
		r.Model = ModelDalle2
	}
	if r.N == nil {
		n := 1
		r.N = &n
	}
	if r.Size == "" {
		if r.Model == ModelGPTImage1 {
			r.Size = ImageSizeAuto
		} else {
			r.Size = ImageSize1024x1024
		}
	}
	if r.Quality == "" {
		r.Quality = ImageQualityAuto
	}
	if r.Style == "" && r.Model == ModelDalle3 {
		r.Style = ImageStyleVivid
	}
	if r.ResponseFormat == "" && r.Model != ModelGPTImage1 {
		r.ResponseFormat = ImageResponseFormatURL
	}
	if r.Background == "" && r.Model == ModelGPTImage1 {
		r.Background = ImageBackgroundAuto
	}
	if r.Moderation == "" && r.Model == ModelGPTImage1 {
		r.Moderation = ImageModerationAuto
	}
	if r.OutputFormat == "" && r.Model == ModelGPTImage1 {
		r.OutputFormat = ImageOutputFormatPNG
	}
	if r.OutputCompression == nil && r.Model == ModelGPTImage1 {
		compression := 100
		r.OutputCompression = &compression
	}
	if r.PartialImages == nil && r.Model == ModelGPTImage1 {
		partialImages := 0
		r.PartialImages = &partialImages
	}
	if r.Stream == nil && r.Model == ModelGPTImage1 {
		stream := false
		r.Stream = &stream
	}

	// Validate prompt
	if strings.TrimSpace(r.Prompt) == "" {
		return errors.New("prompt is required and cannot be empty")
	}

	// Validate prompt length based on model
	var maxPromptLength int
	switch r.Model {
	case ModelGPTImage1:
		maxPromptLength = 32000
	case ModelDalle2:
		maxPromptLength = 1000
	case ModelDalle3:
		maxPromptLength = 4000
	default:
		return fmt.Errorf("invalid model: %s. Supported models are %s, %s, and %s", r.Model, ModelDalle2, ModelDalle3, ModelGPTImage1)
	}
	if len(r.Prompt) > maxPromptLength {
		return fmt.Errorf("prompt cannot exceed %d characters for model %s", maxPromptLength, r.Model)
	}

	// Validate model
	switch r.Model {
	case ModelDalle2, ModelDalle3, ModelGPTImage1:
		// Valid models
	default:
		return fmt.Errorf("invalid model: %s. Supported models are %s, %s, and %s", r.Model, ModelDalle2, ModelDalle3, ModelGPTImage1)
	}

	// Validate N based on model
	if r.N != nil {
		if *r.N < 1 {
			return errors.New("n must be at least 1")
		}
		switch r.Model {
		case ModelDalle3:
			if *r.N != 1 {
				return errors.New("dall-e-3 can only generate 1 image at a time")
			}
		case ModelDalle2, ModelGPTImage1:
			if *r.N > 10 {
				return fmt.Errorf("%s can generate at most 10 images at a time", r.Model)
			}
		}
	}

	// Validate size based on model
	validSizes := map[string][]string{
		ModelDalle2:    {ImageSize256x256, ImageSize512x512, ImageSize1024x1024},
		ModelDalle3:    {ImageSize1024x1024, ImageSize1792x1024, ImageSize1024x1792},
		ModelGPTImage1: {ImageSize1024x1024, ImageSize1536x1024, ImageSize1024x1536, ImageSizeAuto},
	}

	modelSizes, exists := validSizes[r.Model]
	if !exists {
		return fmt.Errorf("unsupported model: %s", r.Model)
	}

	if !slices.Contains(modelSizes, r.Size) {
		return fmt.Errorf("invalid size for model %s: %s. Supported sizes are %v", r.Model, r.Size, modelSizes)
	}

	// Validate quality based on model
	validQualities := map[string][]string{
		ModelDalle2:    {ImageQualityStandard, ImageQualityAuto},
		ModelDalle3:    {ImageQualityStandard, ImageQualityHD, ImageQualityAuto},
		ModelGPTImage1: {ImageQualityAuto, ImageQualityHigh, ImageQualityMedium, ImageQualityLow},
	}

	modelQualities, exists := validQualities[r.Model]
	if !exists {
		return fmt.Errorf("unsupported model: %s", r.Model)
	}

	if !slices.Contains(modelQualities, r.Quality) {
		return fmt.Errorf("invalid quality for model %s: %s. Supported qualities are %v", r.Model, r.Quality, modelQualities)
	}

	// Validate style (only for DALL-E 3)
	if r.Model != ModelDalle3 && r.Style != "" {
		return fmt.Errorf("style parameter is only supported for %s", ModelDalle3)
	}
	if r.Model == ModelDalle3 {
		switch r.Style {
		case ImageStyleVivid, ImageStyleNatural:
			// Valid styles
		default:
			return fmt.Errorf("invalid style for %s: %s. Supported styles are %s and %s", ModelDalle3, r.Style, ImageStyleVivid, ImageStyleNatural)
		}
	}

	// Validate response format (not supported for GPT-Image-1)
	if r.Model == ModelGPTImage1 && r.ResponseFormat != "" {
		return fmt.Errorf("response_format parameter is not supported for %s", ModelGPTImage1)
	}
	if r.Model != ModelGPTImage1 {
		switch r.ResponseFormat {
		case ImageResponseFormatURL, ImageResponseFormatB64JSON:
			// Valid formats
		default:
			return fmt.Errorf("invalid response_format: %s. Supported formats are %s and %s", r.ResponseFormat, ImageResponseFormatURL, ImageResponseFormatB64JSON)
		}
	}

	// Validate GPT-Image-1 specific parameters
	if r.Model == ModelGPTImage1 {
		// Validate background
		switch r.Background {
		case ImageBackgroundAuto, ImageBackgroundTransparent, ImageBackgroundOpaque:
			// Valid backgrounds
		default:
			return fmt.Errorf("invalid background for %s: %s. Supported backgrounds are %s, %s, and %s", ModelGPTImage1, r.Background, ImageBackgroundAuto, ImageBackgroundTransparent, ImageBackgroundOpaque)
		}

		// Validate moderation
		switch r.Moderation {
		case ImageModerationAuto, ImageModerationLow:
			// Valid moderation levels
		default:
			return fmt.Errorf("invalid moderation for %s: %s. Supported moderation levels are %s and %s", ModelGPTImage1, r.Moderation, ImageModerationAuto, ImageModerationLow)
		}

		// Validate output format
		switch r.OutputFormat {
		case ImageOutputFormatPNG, ImageOutputFormatJPEG, ImageOutputFormatWEBP:
			// Valid output formats
		default:
			return fmt.Errorf("invalid output_format for %s: %s. Supported formats are %s, %s, and %s", ModelGPTImage1, r.OutputFormat, ImageOutputFormatPNG, ImageOutputFormatJPEG, ImageOutputFormatWEBP)
		}

		// Validate output compression
		if r.OutputCompression != nil {
			if *r.OutputCompression < 0 || *r.OutputCompression > 100 {
				return fmt.Errorf("output_compression must be between 0 and 100, got %d", *r.OutputCompression)
			}
			// Output compression is only valid for webp and jpeg
			if r.OutputFormat != ImageOutputFormatWEBP && r.OutputFormat != ImageOutputFormatJPEG {
				return fmt.Errorf("output_compression is only supported for %s and %s output formats", ImageOutputFormatWEBP, ImageOutputFormatJPEG)
			}
		}

		// Validate partial images
		if r.PartialImages != nil {
			if *r.PartialImages < 0 || *r.PartialImages > 3 {
				return fmt.Errorf("partial_images must be between 0 and 3, got %d", *r.PartialImages)
			}
		}

		// Validate stream
		// No additional validation needed for stream boolean
	}

	// Validate non-GPT-Image-1 parameters are not used with GPT-Image-1
	if r.Model == ModelGPTImage1 {
		if r.Style != "" {
			return fmt.Errorf("style parameter is not supported for %s", ModelGPTImage1)
		}
	}

	// Validate non-GPT-Image-1 parameters are not used with other models
	if r.Model != ModelGPTImage1 {
		if r.Background != "" {
			return fmt.Errorf("background parameter is only supported for %s", ModelGPTImage1)
		}
		if r.Moderation != "" {
			return fmt.Errorf("moderation parameter is only supported for %s", ModelGPTImage1)
		}
		if r.OutputFormat != "" {
			return fmt.Errorf("output_format parameter is only supported for %s", ModelGPTImage1)
		}
		if r.OutputCompression != nil {
			return fmt.Errorf("output_compression parameter is only supported for %s", ModelGPTImage1)
		}
		if r.PartialImages != nil {
			return fmt.Errorf("partial_images parameter is only supported for %s", ModelGPTImage1)
		}
		if r.Stream != nil {
			return fmt.Errorf("stream parameter is only supported for %s", ModelGPTImage1)
		}
	}

	return nil
}

// ImageGenerationResponse represents a response from the OpenAI Images API.
// Reference: https://platform.openai.com/docs/api-reference/images/object
type ImageGenerationResponse struct {
	// Created: The Unix timestamp (in seconds) for when the image generation request was created.
	Created JSONUNIXTime `json:"created"`

	// Data: A list of generated images.
	Data []ImageData `json:"data"`

	// Background: Background used for generation (transparent or opaque). GPT-Image-1 only.
	Background string `json:"background,omitempty"`

	// Model: The model used for the image generation.
	Model string `json:"model,omitempty"`

	// OutputFormat: Output format of the image (png, webp, jpeg).
	OutputFormat string `json:"output_format,omitempty"`

	// Quality: Quality of the generated image (low, medium, high).
	Quality string `json:"quality,omitempty"`

	// Size: Size of the generated image.
	Size string `json:"size,omitempty"`

	// Usage: Token usage information. Present for GPT-Image-1 only.
	Usage *ImageUsage `json:"usage,omitempty"`
}

// ImageData represents a single generated image in the response.
type ImageData struct {
	// URL: The URL of the generated image, if response_format is url (default).
	URL *string `json:"url,omitempty"`

	// B64JSON: The base64-encoded JSON of the generated image, if response_format is b64_json.
	B64JSON *string `json:"b64_json,omitempty"`

	// RevisedPrompt: The prompt that was used to generate the image, if there was any revision to the provided prompt.
	RevisedPrompt string `json:"revised_prompt,omitempty"`
}

// ImageUsage represents token usage for image generation (GPT-Image-1 only).
type ImageUsage struct {
	// InputTokens: Number of tokens (images and text) in the input prompt.
	InputTokens int `json:"input_tokens"`

	// InputTokensDetails: Detailed breakdown of input tokens.
	// Shape varies by provider; represented as a string->int map for flexibility.
	InputTokensDetails map[string]int `json:"input_tokens_details,omitempty"`

	// OutputTokens: Number of output tokens generated by the model.
	OutputTokens int `json:"output_tokens"`

	// TotalTokens: Total number of tokens (images and text) used.
	TotalTokens int `json:"total_tokens"`
}

// ImageGenerationError represents an error response from the OpenAI Images API.
type ImageGenerationError struct {
	// Error contains the error details.
	Error struct {
		// Type: The type of error.
		Type string `json:"type"`

		// Message: A human-readable error message.
		Message string `json:"message"`

		// Code: An optional error code.
		Code *string `json:"code,omitempty"`

		// Param: The parameter that caused the error, if applicable.
		Param *string `json:"param,omitempty"`
	} `json:"error"`
}

// IsDalle3Model checks if the given model is DALL-E 3.
func IsDalle3Model(model string) bool {
	return model == ModelDalle3
}

// IsGPTImage1Model checks if the given model is GPT-Image-1.
func IsGPTImage1Model(model string) bool {
	return model == ModelGPTImage1
}

// GetDefaultImageSize returns the default image size for the given model.
func GetDefaultImageSize(model string) string {
	switch model {
	case ModelGPTImage1:
		return ImageSizeAuto
	case ModelDalle3, ModelDalle2:
		return ImageSize1024x1024
	default:
		return ImageSize1024x1024
	}
}

// GetMaxImagesForModel returns the maximum number of images that can be generated for the given model.
func GetMaxImagesForModel(model string) int {
	if IsDalle3Model(model) {
		return 1
	}
	return 10
}

// ValidateImageSize validates if the given size is supported for the given model.
func ValidateImageSize(model, size string) error {
	validSizes := map[string][]string{
		ModelDalle2:    {ImageSize256x256, ImageSize512x512, ImageSize1024x1024},
		ModelDalle3:    {ImageSize1024x1024, ImageSize1792x1024, ImageSize1024x1792},
		ModelGPTImage1: {ImageSize1024x1024, ImageSize1536x1024, ImageSize1024x1536, ImageSizeAuto},
	}

	modelSizes, exists := validSizes[model]
	if !exists {
		return fmt.Errorf("unsupported model: %s", model)
	}

	if slices.Contains(modelSizes, size) {
		return nil
	}

	return fmt.Errorf("invalid size for model %s: %s. Supported sizes are %v", model, size, modelSizes)
}

// String implements fmt.Stringer for ImageGenerationResponse.
func (r *ImageGenerationResponse) String() string {
	buf, _ := json.Marshal(r)
	return strings.ReplaceAll(string(buf), ",", ", ")
}

// MarshalJSON implements json.Marshaler for ImageGenerationRequest.
// This ensures proper JSON serialization with defaults applied.
func (r ImageGenerationRequest) MarshalJSON() ([]byte, error) {
	// Create a copy to avoid modifying the original
	req := r

	// Apply defaults if not set
	if req.Model == "" {
		req.Model = ModelDalle2
	}
	if req.N == nil {
		n := 1
		req.N = &n
	}
	if req.Size == "" {
		if req.Model == ModelGPTImage1 {
			req.Size = ImageSizeAuto
		} else {
			req.Size = ImageSize1024x1024
		}
	}
	if req.Quality == "" {
		req.Quality = ImageQualityAuto
	}
	if req.Style == "" && req.Model == ModelDalle3 {
		req.Style = ImageStyleVivid
	}
	if req.ResponseFormat == "" && req.Model != ModelGPTImage1 {
		req.ResponseFormat = ImageResponseFormatURL
	}
	if req.Background == "" && req.Model == ModelGPTImage1 {
		req.Background = ImageBackgroundAuto
	}
	if req.Moderation == "" && req.Model == ModelGPTImage1 {
		req.Moderation = ImageModerationAuto
	}
	if req.OutputFormat == "" && req.Model == ModelGPTImage1 {
		req.OutputFormat = ImageOutputFormatPNG
	}
	if req.OutputCompression == nil && req.Model == ModelGPTImage1 {
		compression := 100
		req.OutputCompression = &compression
	}
	if req.PartialImages == nil && req.Model == ModelGPTImage1 {
		partialImages := 0
		req.PartialImages = &partialImages
	}
	if req.Stream == nil && req.Model == ModelGPTImage1 {
		stream := false
		req.Stream = &stream
	}

	// Use reflection-like approach to marshal
	type Alias ImageGenerationRequest
	return json.Marshal((*Alias)(&req))
}

// UnmarshalJSON implements json.Unmarshaler for ImageGenerationRequest.
func (r *ImageGenerationRequest) UnmarshalJSON(data []byte) error {
	type Alias ImageGenerationRequest
	aux := &struct {
		*Alias
	}{
		Alias: (*Alias)(r),
	}
	if err := json.Unmarshal(data, aux); err != nil {
		return err
	}
	return nil
}
