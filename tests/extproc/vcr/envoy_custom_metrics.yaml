# Copyright Envoy AI Gateway Authors
# SPDX-License-Identifier: Apache-2.0
# The full text of the Apache license is available in the LICENSE file at
# the root of the repo.

# Same as envoy.yaml with a custom access log format for dynamic metadata.

admin:
  address:
    socket_address:
      address: 127.0.0.1
      port_value: 9901

static_resources:
  listeners:
    - name: listener_0
      address:
        socket_address:
          address: 0.0.0.0
          port_value: 1062
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                stat_prefix: ingress_http
                # Custom access log format to capture dynamic metadata
                access_log:
                  - name: dynamic_metadata
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog
                      log_format:
                        text_format_source:
                          inline_string: "TTFT=%DYNAMIC_METADATA(ai_gateway_llm_ns:token_latency_ttft)% ITL=%DYNAMIC_METADATA(ai_gateway_llm_ns:token_latency_itl)% TEST_COST=%DYNAMIC_METADATA(ai_gateway_llm_ns:test_cost)% ALL=%DYNAMIC_METADATA(ai_gateway_llm_ns)%\n"
                route_config:
                  name: local_route
                  virtual_hosts:
                    - name: backend
                      domains: ["*"]
                      routes:
                        # These paths must match those registered in cmd/extproc/mainlib/main.go
                        - match:
                            path: "/v1/chat/completions"
                          route:
                            cluster: openai
                        - match:
                            path: "/v1/embeddings"
                          route:
                            cluster: openai
                        - match:
                            path: "/v1/models"
                          route:
                            cluster: openai
                        - match:
                            prefix: "/"
                          direct_response:
                            status: 404
                            body:
                              inline_string: 'not forwarding paths except in cmd/extproc/mainlib/main.go'
                          typed_per_filter_config:
                            envoy.filters.http.ext_proc:
                              "@type": type.googleapis.com/envoy.config.route.v3.FilterConfig
                              disabled: true
                http_filters:
                  # Simulate real config injected via EnvoyExtensionPolicy
                  - name: envoy.filters.http.ext_proc
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.ext_proc.v3.ExternalProcessor
                      allow_mode_override: true
                      message_timeout: 5s  # Increase timeout from default 200ms to 5s
                      grpc_service:
                        envoy_grpc:
                          cluster_name: ext_proc
                      processing_mode:
                        request_header_mode: SEND
                        response_header_mode: SEND
                        request_body_mode: BUFFERED
                        response_body_mode: BUFFERED
                      metadataOptions:
                        receivingNamespaces:
                          untyped:
                            - ai_gateway_llm_ns
                  - name: envoy.filters.http.router
                    typed_config:
                      "@type": type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
  clusters:
    - name: openai
      connect_timeout: 5s  # Increase from 0.25s to prevent timeout issues
      type: STRICT_DNS
      lb_policy: ROUND_ROBIN
      typed_extension_protocol_options:
        envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
          "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
          explicit_http_config:
            http_protocol_options: {}
          http_filters:
            - name: upstream_extproc
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.http.ext_proc.v3.ExternalProcessor
                allow_mode_override: true
                message_timeout: 5s  # Increase timeout from default 200ms to 5s
                request_attributes:
                  - xds.upstream_host_metadata
                processing_mode:
                  # AI Gateway upstream extproc configuration (runs after routing)
                  # request_header_mode: SEND - Process request headers to select backend
                  request_header_mode: "SEND"
                  # request_body_mode: NONE - Request body already processed downstream
                  request_body_mode: "NONE"
                  # response_header_mode: SEND - Process response headers for streaming detection
                  # NOTE: Must be SEND (not SKIP) to allow ProcessResponseHeaders to set
                  # mode override to STREAMED for streaming responses
                  response_header_mode: "SEND"
                  # response_body_mode: BUFFERED - Process response body for metrics/costs
                  # NOTE: Standard AI Gateway uses NONE here, but for custom metrics
                  # that need TTFT/ITL, this must be BUFFERED or STREAMED
                  response_body_mode: "BUFFERED"
                grpc_service:
                  envoy_grpc:
                    cluster_name: ext_proc
                metadataOptions:
                  receivingNamespaces:
                    untyped:
                      - ai_gateway_llm_ns
            - name: envoy.filters.http.upstream_codec
              typed_config:
                "@type": type.googleapis.com/envoy.extensions.filters.http.upstream_codec.v3.UpstreamCodec
      load_assignment:
        cluster_name: openai
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: host.docker.internal
                      port_value: 11434
                # Add metadata in prod set by XDS: xds.upstream_host_metadata
                metadata:
                  filter_metadata:
                    aigateway.envoy.io:
                      per_route_rule_backend_name: "openai"
    - name: ext_proc
      connect_timeout: 5s  # Increase from 0.25s to prevent timeout issues
      type: STRICT_DNS
      lb_policy: ROUND_ROBIN
      load_assignment:
        cluster_name: ext_proc
        endpoints:
          - lb_endpoints:
              - endpoint:
                  address:
                    socket_address:
                      address: extproc
                      port_value: 1063
      typed_extension_protocol_options:
        envoy.extensions.upstreams.http.v3.HttpProtocolOptions:
          "@type": type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions
          explicit_http_config:
            http2_protocol_options: {}

